# RCAN_复现历程

## 1.RCAN介绍

### **1.1简介**

在图像超分辨领域，卷积神经网络的深度非常重要，但过深的网络却难以训练。低分辨率的输入以及特征包含丰富的低频信息，但却在通道间被平等对待，因此阻碍了网络的表示能力。为了解决上述问题，作者提出了一个深度残差通道注意力网络（RCAN）。

**作者的三个贡献点：**

- **更深的深度；**
- **残差中残差(RIR)，保留低频信息，使主网络专注于学习高频信息；**
- **提出了通道关注(CA)机制，提高了网络的表示能力；**

### 1.2 网络结构

#### 1.2.1 RG

![RG](https:github.com/gh/XiaoNieLe/Image/202410101945594.png)

一个 RG (残差群）由 B 个 RCAB、一个卷积层和一个 SSC 组成，作者实现的时候，B 取 20，10个RG。

#### 1.2.2 CA



输入是一个 H×W×C 的特征，先进行一个空间的全局平均池化得到一个 1×1×C 的通道描述。然后，再经过一个下采样层和一个上采样层得到每一个通道的权重系数，将权重系数和原来的特征相乘即可得到缩放后的新特征，整个过程实际上就是对不同通道的特征重新进行了加权分配。（下采样和上采样层都利用 1×1 的卷积来实现，下采样层的通道数减少 r 倍，激活函数为 Relu（作者实现基本都是Relu），上采样层的激活函数为 Sigmoid。在论文中，作者采用的通道数 C=64，r = 16。）

#### 1.2.3 RCAB



RCAB （残差通道注意块 ）将CA 和残差思想融合在一起。输入一个特征 input，先进行一个卷积-Relu-卷积操作得到 f，然后 f 再经过一个 CA 模块进行重新缩放得到 x，最后将 x 和 input 相加得到输出特征。残差块的数量设置为200，即10个残差组，每个20个。

#### 1.2.4 评价标准

使用了PSNR、SSIM。PSNR，即峰值信噪比，可以比较SR结果图和ground truth(即原高清大图)之间的差距；SSIM，即结构相似性，可以评价SR的恢复效果，更注重细节恢复。

### 1.3数据集简介

#### 1.3.1DIV2K

├── DIV2K_train_HR
│   ├── 0001.png
│   ├─ ...
│   └── 0900.png
├── DIV2K_train_LR_bicubic
│   ├── X2
│   │   ├── 0001x2.png
│   │   ├─ ...
│   │   └── 0900x2.png
│   ├── X3
│   │   ├── 0001x3.png
│   │   ├─ ...
│   │   └── 0900x3.png
│   └── X4
│       ├── 0001x4.png
│       ├─ ...
│       └── 0900x4.png

## 2.复现过程

### 2.1 搭建环境

相对于作者的环境，有以下三方库依赖变更：

- scipy==1.4.1变更scipy==1.2.1（scipy.misc “模块没有 ”imread "属性）
- intel-openmp==2020.0.133变更intel-openmp==2021.1.1（年代太久远2020.0.133不存在）
- 其他的第三方依赖安装：

```
pip isntall -r requirements.txt
```

### 2.2 环境要求

| 环境          | 版本                          |
| ------------- | ----------------------------- |
| Torch_Version | PyTorch==0.4.0                |
| Ubuntu        | Ubuntu==16.4                  |
| Python3.6     | Python==3.6.13                |
| CUDA          | CUDA==8.0                     |
| 云服务器      | [AutoAL算力云]([AutoDL算力云) |
| GPU           | RTX 2080 Ti                   |

### 2.2作者options.py文件超参数色设置

```
"n_train": 800,                      # 训练集数量
"n_val": 5,                          # 验证集数量
"offset_val": 800,                   # 验证集索引偏移 800-805
"lr": 0.0001,                        # 学习率
"epochs": 1000,                      # 训练轮次数
"batch_size": 16,                    # 输入张量的批次大小
"weight_decay": 0,                   # 权重衰减
"betas":(0.9, 0.999),                # ADAM beta1 beta2
"test_every":1000,                   # 每N批进行一次试验
"n_resgroups":10,                    # 残差组数
"reduction":16,                      # 特征映射数减少
"patch_size":192,                    # 输出块大小
”rgb_range“:255, 				     # RGB图像的像素值范
”act“:relu, 				         # 激活函数
"scale":'4',                         # 超分辨率比例尺,可选2,3,4,8
"n_colors":3,                        # 颜色通道数
"n_resblocks":20,                    # 残差块数
"n_feats":64,                        # 特诊图数量
"res_scale":1,                       # 残差缩放因子
"lr_decay":200,                      # 每N个epoch学习率衰减一次
"optimizer":ADAM,                    # 优化器类型
```

通过修改部分超参数达到训练不同模型的目的。

CUDNN_STATUS_EXECUTION_FAILED的解决方法：不用 cudnn 加速

```python
torch.backends.cudnn.enabled = False
```

## 3.重新训练模型

修改训练集，重新训练得到我们想要的模型，再用得到的模型测试新的数据集。打算使用[UC Merced Land Use Dataset]([UC Merced Land Use Dataset](http://weegee.vision.ucmerced.edu/datasets/landuse.html))重新训练，对[RS_C11](https://pan.baidu.com/s/1mhagndY))数据集测试。(还在训练中，结果还没得到)

### 3.1UCMerced_LandUse

├── XiaoNie_train_HR
│   ├── 0001.tif
│   ├─ ...
│   └── .tif
├── XiaoNie_train_LR_bicubic
│   ├── X2
│   │   ├── 0001x2.tif
│   │   ├─ ...
│   │   └── 2100x2.tif
│   ├── X3
│   │   ├── 0001x3.tif
│   │   ├─ ...
│   │   └── 2100x3.tif
│   └── X4
│       ├── 0001x4.tif
│       ├─ ...
│       └── 2100x4.tif

训练scale为2, 3, 4, 8

```
# BI, scale 2, 3, 4, 8
# RCAN_BIX2_G10R20P48, input=48x48, output=96x96
python main.py --model RCAN --save RCAN_BIX2_G10R20P48 --scale 2 --n_resgroups 10 --n_resblocks 20 --n_feats 64  --reset --chop --save_results --print_model --patch_size 96

# RCAN_BIX3_G10R20P48, input=48x48, output=144x144
python main.py --model RCAN --save RCAN_BIX3_G10R20P48 --scale 3 --n_resgroups 10 --n_resblocks 20 --n_feats 64  --reset --chop --save_results --print_model --patch_size 144 --pre_train ../experiment/model/RCAN_BIX2.pt

# RCAN_BIX4_G10R20P48, input=48x48, output=192x192
python main.py --model RCAN --save RCAN_BIX4_G10R20P48 --scale 4 --n_resgroups 10 --n_resblocks 20 --n_feats 64  --reset --chop --save_results --print_model --patch_size 192 --pre_train ../experiment/model/RCAN_BIX2.pt

# RCAN_BIX8_G10R20P48, input=48x48, output=384x384
python main.py --model RCAN --save RCAN_BIX8_G10R20P48 --scale 8 --n_resgroups 10 --n_resblocks 20 --n_feats 64  --reset --chop --save_results --print_model --patch_size 384 --pre_train ../experiment/model/RCAN_BIX2.pt

# RCAN_BDX3_G10R20P48, input=48x48, output=144x144
# specify '--dir_data' to the path of BD training data
python main.py --model RCAN --save RCAN_BIX3_G10R20P48 --scale 3 --n_resgroups 10 --n_resblocks 20 --n_feats 64  --reset --chop --save_results --print_model --patch_size 144 --pre_train ../experiment/model/RCAN_BIX2.pt
```

## 4.心得

为了完成这次顾老师给的任务，感触和学到的东西有很多。虽然这只是一个很简单的任务，但是我却花了很多的时间，也说明我需要学习和成长的地方还有很多。

这段时间每天都在学习，时间过得很快，很紧凑，生活和学习都有了目标和动力，不再是像以往没有目标的乱打乱撞，也有了这三年的时间计划，所以我想在这个方向上努力的学习下去。我明白和组间的同学有了一年的差距，所以我更不敢怠慢下去，我跑的不快，但是我会一直跑。

在完成这次任务的过程中，遇到了很多的问题和困难，也都是我以前没有遇到的，在解决这些困难的过程中很费时，很费劲，但当我每解决一个时候，我都会感到很快乐，感觉离成功复现不远了。我整个过程就是：配环境->失败（沮丧）->网上找方法->看论文->学习网络框架->配环境->失败->看代码。我也不知道失败了多少次（因为torch的版本太低，没装过这么低的版本）后来成功在服务器上配置好了环境，也成功的将代码运行了起来，那一刻是快乐的，收获很多。

最后就是很感谢顾老师和任老师能给我这一次机会证明自己，虽然完成的不够好，但我还是会继续的学习，以后也会及时完成顾老师安排的任务。





